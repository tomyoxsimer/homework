{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-65785f12279b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-65785f12279b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    jupyter labextension install @shahinrostami/theme-purple-please\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from vi_util import getIndexOfState, getPolicyForGrid, printPolicyForGrid\n",
    "\n",
    "\n",
    "def guh():\n",
    "    \"\"\"\n",
    "    Initialization:\n",
    "\n",
    "    Done: Create a class for a State that has members ‘x’ and ‘y’.\n",
    "    Done: Create a 1D list of State objects for the environment. Don’t forget to exclude the state for position (2,2) because\n",
    "             that position is an obstacle. The states should be in row-major order.\n",
    "    Done: Create a list of actions. This can simply be A=[‘u’, ‘r’, ‘d’, ‘l’]. You just need four elements.\n",
    "    Working: Create a numpy array containing the rewards for each state. Make sure your terminal states have the correct rewards.\n",
    "    Done: Create your transition model matrix (this is given to you in vi_util.py).\n",
    "    Done: Set up the valueIteration function header and return statement (this can return nothing meaningful for now).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#### Initialization ####\n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "enviro = [State(3,1), State(3,2), State(3,3), State(3,4),\n",
    "          State(2,1), State(2,2), State(2,3), State(2,4),\n",
    "          State(1,1), State(1,2), State(1,3), State(1,4)]\n",
    "\n",
    "rewards = np.array([[-.04,-.04,-.04,1], [-.04, \"?\",-.04,-1], [-.04,-.04,-.04,-.04]])\n",
    "\n",
    "print(enviro)\n",
    "print(rewards)\n",
    "\n",
    "A = ['u', 'r', 'd', 'l']\n",
    "\n",
    "\n",
    "def valueIterations(S, A, P, R_states, discount, tr):\n",
    "    \"\"\"\n",
    "\n",
    "    :param S:\n",
    "    :param A:\n",
    "    :param P:\n",
    "    :param R_states:\n",
    "    :param discount:\n",
    "    :param tr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def guh2():\n",
    "    \"\"\"\n",
    "    Create a numpy array called U to hold a utility value for each state.\n",
    "    Set the rewards for the terminal states.\n",
    "    Create a numpy array called U_prime to hold updated utility values for each state.\n",
    "    Work on function: getExpectedUtility()\n",
    "    Needed: index of action, index of state, transition model, utility vector/list/array (the utility value for each state), set of states\n",
    "\n",
    "\n",
    "    Set up the Bellman equation for a single state and action.\n",
    "    This will require several things to do.\n",
    "    Set U’ for a single state.\n",
    "    Calculate U’ for all states.\n",
    "    Set up the main loop in valueIteration\n",
    "    Calculate delta, which is the maximum difference between U’ and U in an iteration.\n",
    "    Terminate loop once greatest change is smaller than threshold\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "##def getExpectedUtility(???):\n",
    "\n",
    "\n",
    "#### Below is provided by class ####\n",
    "\n",
    "# Call value iteration function\n",
    "##U = valueIterations(S, A, P, R_states, discount, tr)\n",
    "print('\\n\\n\\n')\n",
    "##print('Utilities: \\n%s' % U)\n",
    "\n",
    "# List of terminal state indices\n",
    "i_terminals = [6, 10]\n",
    "\n",
    "##policy = getPolicyForGrid(S, U, A, i_terminals)\n",
    "print('Policy: %s' % policy)\n",
    "\n",
    "# Print the policy\n",
    "# Last parameter is list of obstacle indices\n",
    "##printPolicyForGrid(policy, w, h, [5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
